{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeongug-il/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeongug-il/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== '\"인사행정\"' 검색에 대한 크롤링 시작 =====\n",
      "'\"인사행정\"' 검색에 대한 브라우저를 열었습니다.\n",
      "네이버 뉴스 페이지로 이동했습니다. 검색어: \"인사행정\"\n",
      "첫 번째 기사 로드 완료\n",
      "스크롤 완료. 모든 기사가 로드되었습니다.\n",
      "기사 1 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 2 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 3 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 4 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 5 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 6 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 7 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 8 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 9 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 10 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 11 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 12 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 13 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 14 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 15 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 16 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 17 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 18 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 19 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 20 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 21 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 22 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 23 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 24 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 25 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 26 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 27 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 28 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 29 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 30 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 31 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 32 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 33 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 34 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 35 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 36 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 37 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "기사 38 크롤링 중...\n",
      "기사 본문 크롤링 완료\n",
      "'\"인사행정\"'에 대한 크롤링 완료. 크롤링한 기사 수: 38\n",
      "'\"인사행정\"' 검색에 대한 브라우저를 닫지 않습니다. (디버깅용)\n",
      "'\"인사행정\"' 검색 결과가 'KBS_인사행정/KBS-인사행정.csv'에 저장되었습니다.\n",
      "===== '\"인사행정\"' 검색에 대한 크롤링 완료 =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# 시간 정보를 날짜로 변환하는 함수\n",
    "def convert_time_to_date(time):\n",
    "    now = datetime.now()\n",
    "    \n",
    "    if \"분 전\" in time:\n",
    "        return now.strftime(\"%Y-%m-%d\")\n",
    "    elif \"시간 전\" in time:\n",
    "        hours_ago = int(time.split(\"시간 전\")[0])\n",
    "        return (now - timedelta(hours=hours_ago)).strftime(\"%Y-%m-%d\")\n",
    "    elif \"일 전\" in time:\n",
    "        days_ago = int(time.split(\"일 전\")[0])\n",
    "        return (now - timedelta(days=days_ago)).strftime(\"%Y-%m-%d\")\n",
    "    elif \"주 전\" in time:\n",
    "        weeks_ago = int(time.split(\"주 전\")[0])\n",
    "        return (now - timedelta(weeks_ago)).strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        return time\n",
    "\n",
    "# 크롤링 함수\n",
    "def crawl_news(query, media):\n",
    "    options = Options()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    print(f\"'{query}' 검색에 대한 브라우저를 열었습니다.\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        # 네이버 뉴스 페이지로 이동\n",
    "        url = f\"https://search.naver.com/search.naver?where=news&query={query}&sm=tab_opt&sort=1&photo=0&field=0&pd=3&ds=2019.08.27&de=2024.08.27&docid=&related=0&mynews=1&office_type=1&office_section_code=2&news_office_checked=1056&nso=so%3Add%2Cp%3Afrom20190827to20240827&is_sug_officeid=0&office_category=0&service_area=0\"\n",
    "        driver.get(url)\n",
    "        print(f\"네이버 뉴스 페이지로 이동했습니다. 검색어: {query}\")\n",
    "\n",
    "        # 첫 번째 기사가 로드될 때까지 대기\n",
    "        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".list_news .bx\")))\n",
    "        print(\"첫 번째 기사 로드 완료\")\n",
    "\n",
    "        # 스크롤이 끝까지 내려갔는지 확인하면서 스크롤을 반복적으로 내림\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        print(\"스크롤 완료. 모든 기사가 로드되었습니다.\")\n",
    "\n",
    "        articles = driver.find_elements(By.CSS_SELECTOR, \".list_news .bx\")\n",
    "\n",
    "        for i, article in enumerate(articles):\n",
    "            try:\n",
    "                print(f\"기사 {i+1} 크롤링 중...\")\n",
    "                title = article.find_element(By.CSS_SELECTOR, \".news_tit\").text\n",
    "                naver_link = article.find_element(By.CSS_SELECTOR, \"div.info_group a[href^='https://n.news.naver.com']\").get_attribute(\"href\")\n",
    "\n",
    "                time_elements = article.find_elements(By.CSS_SELECTOR, \"span.info\")\n",
    "                time_text = time_elements[1].text if len(time_elements) > 1 else time_elements[0].text if len(time_elements) == 1 else \"시간 정보 없음\"\n",
    "                time_parsed = convert_time_to_date(time_text)\n",
    "\n",
    "                driver.execute_script(\"window.open('');\")  # 새 탭 열기\n",
    "                driver.switch_to.window(driver.window_handles[-1])  # 새 탭으로 전환\n",
    "                driver.get(naver_link)\n",
    "\n",
    "                WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"article#dic_area\")))\n",
    "                content = driver.find_element(By.CSS_SELECTOR, \"article#dic_area\").text\n",
    "\n",
    "                # 따옴표 추가 없이 결과 저장\n",
    "                results.append({\n",
    "                    \"title\": title,\n",
    "                    \"naverLink\": naver_link,\n",
    "                    \"time\": time_parsed,\n",
    "                    \"keyword\": query,\n",
    "                    \"media\": media,\n",
    "                    \"content\": content\n",
    "                })\n",
    "\n",
    "                print(\"기사 본문 크롤링 완료\")\n",
    "                driver.close()  # 현재 탭 닫기\n",
    "                driver.switch_to.window(driver.window_handles[0])  # 다시 검색 결과 탭으로 전환\n",
    "\n",
    "            except StaleElementReferenceException as e:\n",
    "                print(f\"StaleElementReferenceException 발생 (index {i}): {e}. 다음 기사로 넘어갑니다.\")\n",
    "                continue  # 오류 발생 시 해당 기사를 건너뛰고 다음 기사로 넘어갑니다.\n",
    "            except Exception as e:\n",
    "                print(f\"기사 크롤링 중 오류 발생 (index {i}):\", e)\n",
    "                continue\n",
    "\n",
    "        print(f\"'{query}'에 대한 크롤링 완료. 크롤링한 기사 수: {len(results)}\")\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Selenium 작업 중 오류 발생:\", e)\n",
    "        return results  # 현재까지 크롤링된 결과를 반환\n",
    "\n",
    "    finally:\n",
    "        # 브라우저를 닫지 않도록 주석 처리\n",
    "        # driver.quit()\n",
    "        print(f\"'{query}' 검색에 대한 브라우저를 닫지 않습니다. (디버깅용)\")\n",
    "\n",
    "# 검색어 설정\n",
    "query = '\"인사행정\"'\n",
    "media = \"KBS\"  # 미디어 명시적으로 지정\n",
    "\n",
    "# 결과 저장할 폴더 경로\n",
    "folder_name = f\"{media}_{query.replace(' ', '_').replace('\\\"', '')}\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# 명시적으로 지정한 파일 이름 설정\n",
    "file_name = \"KBS-인사행정.csv\"  # 원하는 파일 이름으로 수정\n",
    "\n",
    "# 검색어에 대해 크롤링 수행 및 CSV로 저장\n",
    "print(f\"===== '{query}' 검색에 대한 크롤링 시작 =====\")\n",
    "news_data = crawl_news(query, media)\n",
    "\n",
    "if news_data:\n",
    "    df = pd.DataFrame(news_data)\n",
    "    \n",
    "    # 지정된 파일 이름으로 CSV에 저장\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "    \n",
    "    # 파일 열고 기사 수 추가\n",
    "    with open(file_path, mode='w', encoding='utf-8-sig', newline='') as file:\n",
    "        file.write(f\"# 총 {len(news_data)}개의 기사를 크롤링했습니다.\\n\")  # 주석 형태로 기사 수 추가\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "    print(f\"'{query}' 검색 결과가 '{file_path}'에 저장되었습니다.\")\n",
    "else:\n",
    "    print(f\"'{query}' 검색에서 크롤링된 데이터가 없습니다.\")\n",
    "print(f\"===== '{query}' 검색에 대한 크롤링 완료 =====\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
